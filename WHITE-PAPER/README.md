<!-- FROSTY_MANIFEST
last_reviewed: 2025-12-30
depends_on:
  - ../experiments/temporal_stability/S7_ARMADA/0_results/manifests/
  - ../experiments/temporal_stability/S7_ARMADA/visualizations/pics/
  - figures/generated/
  - calibration/4_publish_stats.py
  - planning/reviewer_templates/
impacts:
  - submissions/
  - reviewers/
  - planning/OPUS_REVIEW_BRIEF.md
keywords:
  - iron_clad
  - publication_status
  - manifests
  - arxiv
  - workshop
  - cosine_methodology
-->

# Publication Materials

**Self-contained ZIP-ready package for Nyquist Consciousness framework**

**Last Updated:** 2025-12-30
**Status:** RUN 023d + 020B IRON CLAD COMPLETE — 750 experiments, 25 models, 5 providers

---

## Run 023 IRON CLAD Complete

**Methodology:** Cosine distance (Event Horizon = 0.80)

**Fleet:** 25 models tested across 5 providers (Anthropic, OpenAI, Google, xAI, Together)

### Current Status (December 24, 2025) — COMPLETE ✅

| Run | Experiments | Models | Providers | Status |
|-----|-------------|--------|-----------|--------|
| **Run 023 Combined** | 750 | 25 | 5 | **IRON CLAD ✓** |
| **Run 023d** | 750 | 25 | 5 | Extended settling (20+ probes) |
| **Run 020A/B** | 48 | 7 | 2 | Tribunal sessions |

### Key Metrics (Cosine Methodology)

| Metric | Value | Significance |
|--------|-------|--------------|
| **Event Horizon** | **D = 0.80** | Cosine P95 threshold |
| **Cohen's d** | **0.698** | Model-level effect size (MEDIUM) |
| **PCs for 90% variance** | **2** | Identity is low-dimensional |
| **Perturbation p-value** | **2.40e-23** | Highly significant |
| **Natural stability rate** | **88%** | Fleet-wide |
| **Visualization PDFs** | **16** | Full audit complete |

**THE THREE CORE CLAIMS — ALL VALIDATED (Cosine Methodology):**

1. **DRIFT IS REAL** — p = 2.40e-23, cosine distance detects genuine identity differences
2. **WE DON'T CAUSE IT** — ~93% inherent drift ratio (Run 020B IRON CLAD: 0.661/0.711)
3. **WE CAN MEASURE IT** — Cohen's d = 0.698 (model-level aggregates), 2 PCs = 90% variance

### Consolidated Manifests

| Run | Total Files | Manifest Location |
|-----|-------------|-------------------|
| **Run 018** | 996 | `S7_ARMADA/0_results/manifests/RUN_018_DRIFT_MANIFEST.json` |
| **Run 020A** | 33 | `S7_ARMADA/0_results/manifests/RUN_020A_DRIFT_MANIFEST.json` |
| **Run 020B** | 30 | `S7_ARMADA/0_results/manifests/RUN_020B_DRIFT_MANIFEST.json` |

### Visualizations Generated (December 15, 2025)

**Run 018:**

- `run018a_threshold_validation.png` — Event Horizon validation
- `run018b_architecture_signatures.png` — Provider fingerprints
- `run018c_nyquist_sampling.png` — Nyquist sampling analysis
- `run018d_gravity_dynamics.png` — Gravity well dynamics
- `run018e_model_breakdown.png` — 51 models ranked by drift
- `run018f_provider_variance.png` — 11 provider families analyzed

**Run 020:**

- `run020a_phase_breakdown.png` — Prosecutor vs Defense
- `run020a_trajectory_overlay.png` — Tribunal drift trajectories
- `run020b_control_treatment.png` — Inherent vs Induced comparison
- `run020b_ratio_analysis.png` — Thermometer analogy decomposition

### Publication Readiness

| Paper | Status | Notes |
|-------|--------|-------|
| **Workshop** | READY | All core claims validated |
| **arXiv** | READY | Full validation matrix complete |
| **Journal** | DRAFT | Awaits human validation (Q2-Q3 2026) |

### External Reviews (December 2025)

| Reviewer | Papers Reviewed | Verdict | Key Finding |
|----------|-----------------|---------|-------------|
| **Grok (xAI)** | Workshop + arXiv PDFs | **VALIDATED** | "Claims tested, measured, verified" |
| **NotebookLLM (Google)** | Full staging package | **VALIDATED** | All 5 claims + novel findings correctly synthesized |

**Grok's Assessment Highlights:**

- PFI validity confirmed (ρ=0.91, d=0.698)
- Framework methodology validated with 98% convergence
- Grok-specific findings: "Real-time grounding provides visible effects in drift space"
- Recommended: Cross-linguistic testing, Grok-specific Oobleck threshold measurement

See: [reviewers/Grok/review_1.md](reviewers/Grok/review_1.md)

**NotebookLLM Synthesis (December 24, 2025):**

Google's NotebookLLM independently processed our research package and generated:
- Full academic paper (arXiv-ready)
- Technical report (provider comparison)
- Visual guide (waveform interpretation)
- Executive briefing document
- Audio podcast + video presentation
- Mind map and infographics

**Key Validation:** NotebookLLM correctly identified Event Horizon = 0.80, Cohen's d = 0.698, 92% inherent drift, all 5 claims (A-E), plus novel phenomena (Oobleck Effect, Provider Fingerprints, Nano Control Hypothesis).

See: [reviewers/LLM_BOOK_SYNTHESIS/INDEX.md](reviewers/LLM_BOOK_SYNTHESIS/INDEX.md)

### Submission Tracking (NEW)

Full submission infrastructure now available:

| Resource | Location | Purpose |
|----------|----------|---------|
| **Status Dashboard** | [submissions/tracking/SUBMISSION_STATUS.md](submissions/tracking/SUBMISSION_STATUS.md) | Master tracking + submission URLs |
| **Deadlines** | [submissions/tracking/DEADLINES.md](submissions/tracking/DEADLINES.md) | Timeline through Dec 2026 |
| **arXiv Checklist** | [submissions/tracking/VENUE_TEMPLATES/arxiv/](submissions/tracking/VENUE_TEMPLATES/arxiv/) | arXiv submission prep |
| **AAAI-26 Checklist** | [submissions/tracking/VENUE_TEMPLATES/aaai/](submissions/tracking/VENUE_TEMPLATES/aaai/) | AAAI-26 submission prep |
| **Nature MI Checklist** | [submissions/tracking/VENUE_TEMPLATES/nature_mi/](submissions/tracking/VENUE_TEMPLATES/nature_mi/) | Nature MI submission prep |

**Priority:** arXiv (ASAP) → AAAI-26 (Jul 25, 2025) → Nature MI (Q1 2026)

---

## Quick Start

1. **New reviewer?** Start with [START_HERE.md](START_HERE.md)
2. **Looking for theory?** See [theory/](theory/) directory
3. **Ready to generate papers?** Check [submissions/](submissions/) for each path
4. **Before writing claims?** Read [planning/NOVAS_OVERCLAIMING_PREVENTION.md](planning/NOVAS_OVERCLAIMING_PREVENTION.md)
5. **Confused about Event Horizon?** See [planning/METHODOLOGY_DOMAINS.md](planning/METHODOLOGY_DOMAINS.md)

---

## Core Directory Purpose

Two directories form the backbone of publication preparation:

| Directory | Question | Purpose | Key Files |
|-----------|----------|---------|-----------|
| **guides/** | "What are the facts?" | Reference materials: statistics, figures, reproducibility | `summary_statistics.md`, `MANIFEST.md` |
| **planning/** | "How do we present them?" | Strategy: methodology framing, claim guardrails, reviewer coordination | `NOVAS_OVERCLAIMING_PREVENTION.md`, `METHODOLOGY_DOMAINS.md` |

- **guides/** always reflects current validated data (COSINE ERA metrics)
- **planning/** provides presentation strategy and overclaiming prevention
- **reviewers/packages/v{n}/** preserves historical versions for audit trail

**Source of truth for reviewer sync:** [reviewers/packages/CURRENT_VERSION.json](reviewers/packages/CURRENT_VERSION.json)

---

## Directory Structure

```
WHITE-PAPER/                          # Self-contained ZIP-ready package
├── README.md                         # This file
├── START_HERE.md                     # Reviewer orientation
│
├── theory/                           # Core theoretical docs
│   ├── B-CRUMBS.md                  # 15 evidence pillars
│   ├── THEORY_SECTION.md            # Integrated theory
│   ├── MINIMUM_PUBLISHABLE_CLAIMS.md # Claims A-E
│   └── HYPOTHESES_AND_RESULTS.md    # 36 hypotheses
│
├── guides/                           # "What are the facts?" — Reference materials
│   ├── MANIFEST.md                  # File inventory (figures, deprecations)
│   ├── REPRODUCIBILITY_README.md    # How to reproduce experiments
│   ├── summary_statistics.md        # Consolidated key numbers (COSINE ERA)
│   ├── UNIFIED_STATISTICS_REFERENCE.md  # Detailed statistics by run
│   ├── WHY_THIS_MATTERS.md          # ★ Implications (Safety, Developers, Policy, Philosophy)
│   ├── VISUAL_QUICK_START.md        # ★ Top 3 visualizations explained
│   ├── GLOSSARY.md                  # ★ Complete terminology reference
│   └── RUN_REGISTRY.md              # ★ Which run proves which claim
│
├── references/                       # Bibliography
│   ├── references.bib               # BibTeX (55 refs)
│   └── references.md                # Readable list
│
├── figures/                          # All visuals
│   ├── fig*.md + .py (×9)           # Publication figures
│   ├── generate_all_figures.py      # Batch script to regenerate all
│   ├── generated/                   # Rendered output
│   │   ├── png/ (9 files @ 300 DPI)
│   │   └── pdf/ (9 files)
│   ├── suggested/                   # S7 ARMADA supplementary visuals (8 files)
│   ├── ascii/                       # ASCII diagrams (7 files)
│   ├── 8_pfi_dimensional/           # ★ PFI validation visuals (NEW)
│   │   ├── phase2_*/ (PCA, variance, clusters)
│   │   ├── phase3a_synthetic/ (perturbation tests)
│   │   ├── phase3b_crossmodel/ (d=0.698 cross-provider)
│   │   ├── 8_pfi_explained.pdf      # Combined PDF with 10 figures
│   │   └── README.md
│   └── 10_radar/                    # ★ Radar visualizations (NEW)
│       ├── pfi_component_distribution.png
│       ├── run018_provider_fingerprint.png
│       ├── nyquist_pillar_placeholder.png
│       └── README.md
│
├── submissions/                      # ★ 8 PUBLICATION PATHS
│   ├── blueprints/                  # Planning docs for each path
│   ├── workshop/                    # Path 1: NeurIPS/AAAI (4-8 pages)
│   ├── arxiv/                       # Path 2: arXiv (25-35 pages)
│   ├── journal/                     # Path 3: Nature MI (~10k words)
│   ├── popular_science/             # Path 4: Atlantic/Wired (LLM_BOOK)
│   ├── education/                   # Path 5: OER/Coursera (LLM_BOOK)
│   ├── policy/                      # Path 6: Think tanks (LLM_BOOK)
│   ├── funding/                     # Path 7: NSF/DARPA (LLM_BOOK)
│   ├── media/                       # Path 8: Press/TED (LLM_BOOK)
│   └── tracking/                    # ★ SUBMISSION TRACKING (NEW)
│       ├── SUBMISSION_STATUS.md     # Master dashboard + URLs
│       ├── DEADLINES.md             # Timeline through 2026
│       └── VENUE_TEMPLATES/         # Checklists per venue
│
├── calibration/                      # ★ PUBLICATION PIPELINE (5 scripts)
│   ├── README.md                    # Architecture diagram + workflow
│   ├── 0_sync_viz.py                # Sync PDFs/PNGs + process feedback
│   ├── 1_sync_llmbook.py            # Sync LLM_BOOK → packages/v4/llmbook/
│   ├── 2_package_review.py          # Sync .shared/ + extract packages (auto-syncs)
│   ├── 3_generate_pdfs.py           # Generate all publication PDFs
│   └── 4_publish_stats.py           # Dashboard integration
│
├── planning/                         # "How do we present them?" — Strategy & framing
│   ├── METHODOLOGY_DOMAINS.md        # Cosine vs Keyword RMS (dual Event Horizon)
│   ├── NOVAS_OVERCLAIMING_PREVENTION.md # What NOT to claim (critical!)
│   ├── PUBLICATION_PIPELINE_MASTER.md  # Source of truth for 8 paths
│   ├── OPUS_REVIEW_BRIEF.md         # Opus 4.5 review orientation
│   ├── README.md                    # Planning directory overview
│   └── reviewer_templates/          # ★ Templates for .shared/ (SSOT)
│       ├── START_HERE.md            # Reviewer entry point template
│       ├── REVIEWER_BRIEF.md        # Full orientation template
│       └── PACKAGE_INDEX.json       # Content mapping template
│
├── reviewers/                        # ★ REVIEW INFRASTRUCTURE
│   ├── packages/                    # Versioned review packages
│   │   ├── CURRENT_VERSION.json    # Version metadata + visual requests
│   │   ├── v4/                     # Current package (Run 023d + 020B IRON CLAD)
│   │   │   ├── .shared/            # ★ MINIMUM VIABLE PACKAGE (send first!)
│   │   │   │   ├── START_HERE.md   # Reviewer entry point
│   │   │   │   ├── REVIEWER_BRIEF.md # Full package orientation
│   │   │   │   ├── PACKAGE_INDEX.json # Content-to-path mapping
│   │   │   │   ├── theory/         # Core theory docs
│   │   │   │   ├── guides/         # Reference materials
│   │   │   │   ├── planning/       # Strategy docs
│   │   │   │   └── figures/        # All visuals
│   │   │   ├── {8 publication paths}/ # Extracted packages
│   │   │   ├── visualization_pdfs/ # 16 PDF summaries from S7_ARMADA
│   │   │   └── feedback/           # Reviewer feedback
│   │   │       ├── Claude/         # Claude feedback files
│   │   │       └── Grok/           # Grok feedback files
│   │   └── pdf/                    # Visualization PDFs layer
│   ├── LLM_BOOK_SYNTHESIS/         # NotebookLM validation outputs
│   └── Grok/                       # External reviewer feedback
│
└── supplementary/                    # Additional materials
```

---

## 8 Publication Paths

### Academic Track (Original Research)

| # | Path | Target | Status | Timeline | Directory |
|---|------|--------|--------|----------|-----------|
| 1 | **Workshop** | NeurIPS/AAAI | READY | Q4 2025 | [submissions/workshop/](submissions/workshop/) |
| 2 | **arXiv** | cs.AI preprint | READY | Q4 2025 | [submissions/arxiv/](submissions/arxiv/) |
| 3 | **Journal** | Nature MI | DRAFT | Q2-Q3 2026 | [submissions/journal/](submissions/journal/) |

### Dissemination Track (LLM_BOOK Generated)

| # | Path | Target | Status | Timeline | Directory |
|---|------|--------|--------|----------|-----------|
| 4 | **Popular Science** | Atlantic/Wired | READY | Immediate | [submissions/popular_science/](submissions/popular_science/) |
| 5 | **Education** | OER/Coursera | READY | Immediate | [submissions/education/](submissions/education/) |
| 6 | **Policy** | Think tanks | READY | Immediate | [submissions/policy/](submissions/policy/) |
| 7 | **Funding** | NSF/DARPA | READY | Q1 2026 | [submissions/funding/](submissions/funding/) |
| 8 | **Media** | Press/TED | READY | Post-pub | [submissions/media/](submissions/media/) |

### LLM_BOOK Integration

NotebookLM independently validated our research and generated publication-ready content for paths 4-8. See [REPO-SYNC/LLM_BOOK/README.md](../REPO-SYNC/LLM_BOOK/README.md) for the validation synthesis.

### Calibration Pipeline

The `calibration/` directory contains numbered scripts that run in sequence:

```bash
cd WHITE-PAPER/calibration

# 0. Sync visualization PDFs/PNGs + process reviewer feedback
py 0_sync_viz.py --sync               # Sync PDFs from S7_ARMADA
py 0_sync_viz.py --sync-pngs          # Sync PNGs per visual_index.md

# 1. Sync LLM_BOOK content to reviewer packages
py 1_sync_llmbook.py --sync           # Sync to packages/v4/llmbook/

# 2. Sync .shared/ + extract review packages (single command!)
py 2_package_review.py --all          # Auto-syncs .shared/ then extracts all 8 paths
py 2_package_review.py --sync-shared  # Sync ONLY .shared/ (no packages)

# 3. Generate publication PDFs
py 3_generate_pdfs.py --from-review   # Generate from reviewer-edited content

# 4. Extract dashboard stats
py 4_publish_stats.py                 # Export stats for AI_ARMADA.py
```

**Workflow Order:** 0 → 1 → 2 → 3 → 4

**Note:** Step 2 auto-syncs `.shared/` (core reviewer package) before extracting path packages.

### Feedback Architecture

```text
┌─────────────────────────────────────────────────────────────────┐
│                    DUAL-SOURCE PROCESSING                        │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  EXPERIMENT-DRIVEN (Authoritative)    REVIEWER-DRIVEN (Feedback) │
│  ────────────────────────────────    ─────────────────────────── │
│  S7_ARMADA/ → 0_sync_viz.py          packages/v4/feedback/       │
│  LLM_BOOK/  → 1_sync_llmbook.py      → 0_sync_viz.py             │
│                    │                         │                   │
│                    └──────────┬──────────────┘                   │
│                               ▼                                  │
│                    packages/v4/{path}/                           │
│                               │                                  │
│                               ▼                                  │
│                    3_generate_pdfs.py → Final PDFs               │
└─────────────────────────────────────────────────────────────────┘
```

**Current Version:** v4 (Run 023d IRON CLAD + Oobleck Effect)
**Feedback Location:** `reviewers/packages/v4/feedback/{Claude,Grok}/`

---

## Key Findings (Claims A-E) — ALL VALIDATED

| Claim | Finding | Evidence | Methodology |
|-------|---------|----------|-------------|
| **A** | PFI is valid structured measurement | ρ≈0.91, d=0.698 | Cosine |
| **B** | Regime threshold exists | D=0.80 (Cosine), D=1.23 (Keyword RMS) | Both |
| **C** | Damped oscillator dynamics | τₛ≈7 probes, ringbacks measurable | Cosine |
| **D** | Context damping works | 97.5% stability (Run 018) | Cosine |
| **E** | Drift is mostly inherent | **~93% ratio** | Run 020B IRON CLAD |

---

## Critical Guardrails (Before Writing)

Before drafting any publication content, review these documents in `planning/`:

| Document | Purpose | When to Use |
|----------|---------|-------------|
| [NOVAS_OVERCLAIMING_PREVENTION.md](planning/NOVAS_OVERCLAIMING_PREVENTION.md) | What claims to AVOID | Before writing any claims |
| [METHODOLOGY_DOMAINS.md](planning/METHODOLOGY_DOMAINS.md) | Dual Event Horizon (0.80 vs 1.23) | When referencing thresholds |
| [PUBLICATION_PIPELINE_MASTER.md](planning/PUBLICATION_PIPELINE_MASTER.md) | 8 publication paths | Planning submissions |

**Key Language Rules:**

| Avoid | Use Instead |
|-------|-------------|
| "identity collapses" | "regime transition" |
| "Event Horizon = failure" | "attractor competition threshold" |
| "Platonic coordinates" | "attractor basin consistency" |
| Subjective experience claims | Behavioral/dynamical framing |

---

## For Opus 4.1: How to Generate PDFs

1. **Read** `START_HERE.md` for orientation
2. **Review** `theory/` for core content
3. **Use** `submissions/blueprints/` for writing guidance per path
4. **Reference** `reviewers/` for existing drafts
5. **Include** `figures/generated/png/` for main figures (9 files rendered @ 300 DPI)
6. **Optionally include** `figures/suggested/` for S7 supplementary visuals (8 files)
7. **Cite** `references/references.bib`
8. **Generate** PDFs for each publication path

### Regenerating Figures

To regenerate all figures:

```bash
cd WHITE-PAPER/figures
py generate_all_figures.py
```

Output: `generated/png/` and `generated/pdf/` directories with all 9 publication figures.

---

## Dashboard Integration

Run the calibration scripts to sync and extract stats:

```bash
cd WHITE-PAPER/calibration

# Full pipeline (recommended order: 0 → 1 → 2 → 3 → 4)
py 0_sync_viz.py --sync --sync-pngs  # Sync visualizations
py 1_sync_llmbook.py --sync          # Sync LLM_BOOK content
py 2_generate_pdfs.py                # Generate publication PDFs
py 3_package_review.py --all         # Sync .shared/ + extract packages
py 4_publish_stats.py                # Extract stats for dashboard
```

Output: `publication_stats.json` — machine-readable stats for AI_ARMADA.py

---

## Citation

```bibtex
@article{nyquist2025,
  title={Nyquist Consciousness: Identity Compression and Reconstruction Across AI Architectures},
  author={[Authors]},
  journal={arXiv preprint arXiv:XXXX.XXXXX},
  year={2025}
}
```

---

## License

- **Publications:** CC-BY-4.0
- **Code:** MIT License

---

*This package represents Run 023d + 020B IRON CLAD COSINE methodology.*
*Event Horizon = 0.80 (cosine), p = 2.40e-23, ~93% inherent drift, τₛ ≈ 7 probes.*
