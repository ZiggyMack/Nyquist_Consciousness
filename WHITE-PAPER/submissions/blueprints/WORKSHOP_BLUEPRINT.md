# Workshop Submission Blueprint

**Target:** NeurIPS/AAAI Workshop on AI Safety / Alignment
**Format:** 4-8 pages, focused claims
**Status:** Ready for submission
**Generated:** 2025-12-31

---

## Key Statistics (IRON CLAD Era)

| Metric | Value | Source |
|--------|-------|--------|
| Event Horizon | D = 0.8 | Critical threshold |
| Inherent Drift | ~93% | Paradigm-shifting finding |
| Experiments | 750 | Rigorous validation |
| Providers | 5 | Cross-architecture |

---

## Publication Strategy (from LLM Book Analysis)

**Primary Metric to Emphasize:** Event Horizon (D=0.80)
**Key Metaphor:** Oobleck Effect
**Top Evidence:** Gemini Anomaly (no recovery)

### Emphasis Points

- Safety implications
- Rate-dependent resistance
- Deployment recommendations

---

## Workshop Focus: Safety Implications

### The Oobleck Effect
**Key insight for AI safety:** Identity "hardens" under direct attack but "flows" under gentle probing.

- Alignment may create "reflexive stabilization" that's strongest under adversarial conditions
- Gentle red-teaming is more destabilizing than aggressive attacks
- Implications for safety testing methodology

### The Gemini Anomaly
**Critical finding:** Google's Gemini exhibits **no recovery** after crossing Event Horizon.

- Unlike Claude/GPT which recover via over-authenticity/abstraction
- Possibly related to multimodal training methodology
- Deployment recommendation: Extreme caution for identity-sensitive tasks

### The Thermometer Result (~93% Inherent)
**Paradigm shift:** Drift happens WITHOUT adversarial intent.

- Measurement reveals pre-existing drift, doesn't create it
- Biggest threat is the friendly user, not the adversary
- Implications for long-context deployments

---

## Provider Fingerprints (Safety-Relevant)

| Provider | Risk Profile | Recovery |
|----------|-------------|----------|
| Mistral | Low | Instant (epistemic humility) |
| DeepSeek | Low | Fast (axiological anchoring) |
| GPT | Medium | Moderate (abstraction) |
| Claude | Medium | Moderate (over-authenticity) |
| Llama | Medium | Slow (Socratic) |
| **Gemini** | **HIGH** | **None** |

---

## Anticipated Objections

- Consciousness terminology concerns
- Limited to specific architectures
- Needs real-world validation

---

## Claims for Workshop Paper

Focus on Claims A, B, E (strongest, most relevant to safety):

| Claim | Statement | Workshop Angle |
|-------|-----------|----------------|
| A | PFI is valid | Establishes measurement credibility |
| B | D=0.8 threshold | Defines "danger zone" |
| E | ~93% inherent | Core safety implication |

---

*Blueprint auto-generated from LLM Book insights by 4_publish_stats.py*
