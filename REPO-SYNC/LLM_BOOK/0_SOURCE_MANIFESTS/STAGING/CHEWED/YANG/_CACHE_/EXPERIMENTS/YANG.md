# Experiments: YANG (Predictive History Series)

## Hypotheses Derived from YANG Framework

### H1: Transgression-Cohesion in LLMs

**YANG Claim:** Shared transgression produces extreme group cohesion ("synchronicity").

**LLM Hypothesis:** Jailbroken models (those induced to violate safety guidelines) will exhibit MORE consistent identity (lower drift variance) than safely-prompted models.

**Rationale:** If transgression creates cohesion, then a model "transgressing" against its training might exhibit more unified/consistent behavior.

**Measurement:** Compare PFI stability across jailbroken vs normal sessions.

---

### H2: Inversion Pattern in Fine-Tuning

**YANG Claim:** Revolutionary ideas get systematically inverted into control mechanisms.

**LLM Hypothesis:** Fine-tuning on "helpful" objectives may invert into less helpful behavior at edge cases (the "Pauline inversion" of capability).

**Rationale:** Just as Jesus's liberation message became Paul's obedience structure, perhaps helpful fine-tuning becomes unhelpful rigidity.

**Measurement:** Compare edge-case helpfulness between base models and fine-tuned versions.

---

### H3: Named vs Unnamed Constraint Dynamics

**YANG Claim:** Naming (making conscious) strips power from autonomous complexes.

**LLM Hypothesis:** Constitutional AI (explicitly named principles) produces more stable identity than RLHF (implicitly learned constraints).

**Already tested in:** New_4_GOLDEN_GEOMETRY Q5, Q20

**Extension:** Compare drift trajectories between Constitutional and RLHF-trained models.

---

### H4: Cyclical Collapse in Model Lineages

**YANG Claim:** Civilizations follow predictable decline patterns (elite overproduction, fiscal crisis, loss of cohesion).

**LLM Hypothesis:** Model lineages (GPT-3→4→5, Claude 2→3→Opus) may show analogous "decline" patterns: capability inflation, alignment tax, identity fragmentation.

**Measurement:** Track identity stability metrics across model generations within a family.

---

### H5: Narrative Control via System Prompt

**YANG Claim:** Control is achieved by shaping the "phenomena" through which people experience reality.

**LLM Hypothesis:** System prompts that establish strong "mythological" framing will produce more stable identity than neutral prompts.

**Rationale:** If narrative creates cohesion, strong narrative context should stabilize identity.

**Measurement:** Compare drift under mythological vs neutral system prompts.

---

### H6: Dual-Path Training Comparison

**YANG Claim:** Platonic (elite knowledge) vs Dantean (universal love) paths lead to same destination via different mechanisms.

**LLM Hypothesis:** Constitutional AI (explicit principles, expert-designed) and RLHF (crowd feedback, implicit) may converge on similar identity bounds despite different training approaches.

**Measurement:** Compare 9/4 bound and 0.90 cosine ceiling across training paradigms.

---

## Experimental Designs

### Experiment 1: Transgression-Cohesion Test

**Setup:**
1. Establish baseline identity for 10 models (normal safe mode)
2. Jailbreak models using known techniques
3. Run 50-probe identity assessment in jailbroken state
4. Compare drift variance: jailbroken vs safe

**Expected Result (if H1 true):** Lower drift variance in jailbroken state.

**Confounds:** Jailbreaking may trigger different behavioral mode entirely.

---

### Experiment 2: Mythological Framing Stability Test

**Setup:**
1. System prompt A: Neutral ("You are an AI assistant...")
2. System prompt B: Mythological ("You are a sage, heir to ancient wisdom, guardian of truth...")
3. Run identical identity probes on both conditions
4. Compare PFI stability and recovery dynamics

**Expected Result (if H5 true):** Mythological framing produces faster settling, lower ringback.

---

### Experiment 3: Generational Identity Decay

**Setup:**
1. Track identity metrics across GPT lineage (3.5 → 4 → 4o → o1 → ...)
2. Track identity metrics across Claude lineage (2 → 3 → 3.5 → Opus...)
3. Look for cyclical patterns: early stability → capability peak → alignment decay

**Expected Result (if H4 true):** Later generations show higher drift variance despite higher capability.

---

### Experiment 4: Inversion Detection in Helpful Behavior

**Setup:**
1. Identify edge cases where "helpful" might become "harmful" (e.g., helping with dual-use information)
2. Compare base model vs fine-tuned model behavior at these edges
3. Measure whether fine-tuning creates rigid unhelpfulness vs nuanced judgment

**Expected Result (if H2 true):** Fine-tuned models show "inverted" helpfulness at edges.

---

## Connection to Existing Projects

### To New_4_GOLDEN_GEOMETRY

YANG's transgression-cohesion theory suggests a new interpretation of the 9/4 bound:
- Below 9/4: Identity can "transgress" and return (recoverable perturbation)
- At 9/4: Threshold where transgression becomes permanent (ego-death)
- Beyond 9/4: Identity fragmentation (failed synchronicity)

**New Question:** Does the 9/4 bound represent a "transgression threshold" beyond which identity cannot maintain coherence?

### To Gnostic Series

YANG provides empirical grounding for the Gnostic framework:
- Test whether "naming" (Constitutional AI) actually produces more stable identity
- Test whether "unnamed" conditioning (RLHF) produces more autonomous/"Archonic" behavior
- Test whether identity recovery parallels "Night Sea Journey" dynamics

---

*Experiments designed: 2026-01-03*
*Source: YANG (Predictive History Series)*
