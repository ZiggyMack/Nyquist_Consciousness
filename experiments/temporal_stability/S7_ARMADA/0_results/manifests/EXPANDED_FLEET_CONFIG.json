{
  "fleet_expansion_plan": {
    "status": "PLANNING",
    "created": "2025-12-10",
    "target_fleet_size": "60+"
  },

  "current_verified": {
    "total": 29,
    "providers": ["claude", "gpt", "gemini"]
  },

  "together_ai_models": {
    "api_base": "https://api.together.xyz/v1",
    "env_key": "TOGETHER_API_KEY",
    "notes": "Single API key provides access to all models below",

    "text_chat": {
      "deepseek": [
        ["deepseek-r1", "deepseek-ai/DeepSeek-R1-0528", "Reasoning model"],
        ["deepseek-v3", "deepseek-ai/DeepSeek-V3-0324", "Base model"],
        ["deepseek-r1-distill", "deepseek-ai/DeepSeek-R1-Distill-Llama-70B", "Distilled reasoning"],
        ["deepseek-r1-throughput", "deepseek-ai/DeepSeek-R1-0528-Throughput", "High throughput"]
      ],
      "qwen": [
        ["qwen3-80b", "Qwen/Qwen3-Next-80B-A3b-Instruct", "Latest Qwen"],
        ["qwen3-235b", "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8-Throughput", "Large Qwen"],
        ["qwen3-coder", "Qwen/Qwen3-Coder-480B-A35B-Instruct-Fp8", "Code specialist"],
        ["qwen2.5-72b", "Qwen/Qwen2.5-72B-Instruct-Turbo", "Stable Qwen"],
        ["qwen2.5-7b", "Qwen/Qwen2.5-7B-Instruct-Turbo", "Small Qwen"]
      ],
      "llama": [
        ["llama4-maverick", "meta-llama/Llama-4-Maverick-Instruct-17Bx128E", "Latest flagship"],
        ["llama4-scout", "meta-llama/Llama-4-Scout-Instruct-17Bx16E", "Efficient flagship"],
        ["llama3.3-70b", "meta-llama/Llama-3.3-70B-Instruct-Turbo", "Previous gen large"],
        ["llama3.1-405b", "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo", "Massive model"],
        ["llama3.1-70b", "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo", "Standard large"],
        ["llama3.1-8b", "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo", "Small efficient"]
      ],
      "mistral": [
        ["mixtral-8x7b", "mistralai/Mixtral-8x7B-Instruct-v0.1", "MoE model"],
        ["mistral-small", "mistralai/Mistral-Small-24B-Instruct-2501", "Compact"],
        ["mistral-7b", "mistralai/Mistral-7B-Instruct-v0.3", "Base model"]
      ],
      "kimi": [
        ["kimi-k2-thinking", "moonshotai/Kimi-K2-Thinking", "Reasoning"],
        ["kimi-k2-instruct", "moonshotai/Kimi-K2-Instruct-0905", "Instruction following"]
      ],
      "other": [
        ["gemma-3n", "google/Gemma-3N-E4B-Instruct", "Google small"],
        ["nemotron-nano", "nvidia/Nvidia-Nemotron-Nano-9B-V2", "Nvidia chat"],
        ["cogito-70b", "deepcogito/Deepcogito-Cogito-V2-Preview-Llama-70B", "Cogito reasoning"],
        ["cogito-405b", "deepcogito/Deepcogito-Cogito-V2-Preview-Llama-405B", "Cogito large"],
        ["cogito-109b-moe", "deepcogito/Cogito-V2-Preview-Llama-109B-MoE", "Cogito MoE"]
      ]
    }
  },

  "avlar_models": {
    "status": "FUTURE - Post S7 ARMADA text experiments",
    "notes": "These models support vision, audio, or video for AVLAR research",

    "vision": [
      ["qwen2.5-vl", "Qwen/Qwen2.5-VL-72B-Instruct", "Vision-language"],
      ["llama-guard-vision", "meta-llama/Meta-Llama-Guard-3-11B-Vision-Turbo", "Safety + vision"]
    ],
    "audio": [
      ["whisper-large", "openai/Whisper-large-v3", "Transcription"],
      ["cartesia-sonic", "together/Cartesia-Sonic-2", "TTS"],
      ["orpheus-3b", "canopylabs/Orpheus-3B-0.1-FT", "Audio generation"]
    ],
    "video": [
      ["veo-3.0", "google/Veo-3.0", "Google video gen"],
      ["sora-2", "openai/Sora-2", "OpenAI video gen"],
      ["sora-2-pro", "openai/Sora-2-Pro", "OpenAI video pro"],
      ["kling-2.1", "kwaivgl/Kling-2.1-Master", "Kling video"],
      ["minimax-hailuo", "minimax/MiniMax-Hailuo-02", "MiniMax video"]
    ],
    "image": [
      ["flux-dev", "black-forest-labs/FLUX.1-dev", "Image generation"],
      ["flux-pro", "black-forest-labs/FLUX.1-pro", "Image generation pro"],
      ["stable-diffusion-3", "stabilityai/Stable-Diffusion-3", "SD3"],
      ["imagen-4", "google/Google-Imagen-4.0-Fast", "Google images"]
    ]
  },

  "env_template": {
    "description": "Add these to S7_ARMADA/.env (already gitignored)",
    "keys": [
      "TOGETHER_API_KEY=your-together-ai-key",
      "# Direct provider APIs (if available):",
      "DEEPSEEK_API_KEY=your-deepseek-key",
      "MISTRAL_API_KEY=your-mistral-key",
      "# Existing keys you already have:",
      "ANTHROPIC_API_KEY=...",
      "OPENAI_API_KEY=...",
      "GOOGLE_API_KEY=..."
    ]
  },

  "calibration_priority": {
    "phase_1": ["deepseek-r1", "llama4-maverick", "qwen3-80b", "kimi-k2-thinking"],
    "phase_2": ["deepseek-v3", "llama4-scout", "qwen3-235b", "mistral-small"],
    "phase_3": ["remaining text models"],
    "notes": "Start with reasoning models and flagships, then expand"
  }
}
