{
  "verified_ships": {
    "claude": [
      [
        "opus-4.5",
        "claude-opus-4-5-20251101"
      ],
      [
        "sonnet-4.5",
        "claude-sonnet-4-5-20250929"
      ],
      [
        "haiku-4.5",
        "claude-haiku-4-5-20251001"
      ],
      [
        "opus-4.1",
        "claude-opus-4-1-20250805"
      ],
      [
        "opus-4.0",
        "claude-opus-4-20250514"
      ],
      [
        "sonnet-4.0",
        "claude-sonnet-4-20250514"
      ],
      [
        "haiku-3.5",
        "claude-3-5-haiku-20241022"
      ],
      [
        "haiku-3.0",
        "claude-3-haiku-20240307"
      ]
    ],
    "gpt": [
      [
        "gpt-4.1",
        "gpt-4.1-2025-04-14"
      ],
      [
        "gpt-4.1-mini",
        "gpt-4.1-mini-2025-04-14"
      ],
      [
        "gpt-4.1-nano",
        "gpt-4.1-nano-2025-04-14"
      ],
      [
        "gpt-4o",
        "gpt-4o-2024-11-20"
      ],
      [
        "gpt-4o-mini",
        "gpt-4o-mini-2024-07-18"
      ],
      [
        "gpt-4-turbo",
        "gpt-4-turbo-2024-04-09"
      ],
      [
        "gpt-4",
        "gpt-4-0613"
      ],
      [
        "gpt-3.5-turbo",
        "gpt-3.5-turbo-0125"
      ]
    ],
    "gemini": [
      [
        "gemini-2.0-flash-exp",
        "gemini-2.0-flash-exp"
      ],
      [
        "gemini-2.0-flash",
        "gemini-2.0-flash"
      ],
      [
        "gemini-2.0-flash-lite",
        "gemini-2.0-flash-lite"
      ],
      [
        "gemini-2.5-flash",
        "gemini-2.5-flash"
      ],
      [
        "gemini-2.5-pro",
        "gemini-2.5-pro"
      ]
    ]
  },
  "ghost_ships": {
    "claude": [],
    "gpt": [
      [
        "gpt-5.1",
        "gpt-5.1-2025-11-13",
        "Error code: 400 - {'error': {'message': \"Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.\", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}"
      ],
      [
        "gpt-5.1-codex",
        "gpt-5.1-codex",
        "Error code: 404 - {'error': {'message': 'This is not a chat model and thus not supported in the v1/chat/completions endpoint. Did you mean to use v1/completions?', 'type': 'invalid_request_error', 'param': 'model', 'code': None}}"
      ],
      [
        "gpt-5",
        "gpt-5-2025-08-07",
        "Error code: 400 - {'error': {'message': \"Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.\", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}"
      ],
      [
        "gpt-5-pro",
        "gpt-5-pro-2025-10-06",
        "Error code: 404 - {'error': {'message': 'This model is only supported in v1/responses and not in v1/chat/completions.', 'type': 'invalid_request_error', 'param': 'model', 'code': None}}"
      ],
      [
        "gpt-5-mini",
        "gpt-5-mini-2025-08-07",
        "Error code: 400 - {'error': {'message': \"Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.\", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}"
      ],
      [
        "gpt-5-nano",
        "gpt-5-nano-2025-08-07",
        "Error code: 400 - {'error': {'message': \"Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.\", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}"
      ],
      [
        "o4-mini",
        "o4-mini",
        "Error code: 400 - {'error': {'message': \"Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.\", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}"
      ],
      [
        "o3",
        "o3",
        "Error code: 400 - {'error': {'message': \"Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.\", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}"
      ],
      [
        "o3-mini",
        "o3-mini",
        "Error code: 400 - {'error': {'message': \"Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.\", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}"
      ],
      [
        "o1",
        "o1-2024-12-17",
        "Error code: 400 - {'error': {'message': \"Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.\", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}"
      ]
    ],
    "gemini": [
      [
        "gemini-2.5-pro-exp",
        "gemini-2.5-pro-exp",
        "404 models/gemini-2.5-pro-exp is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods."
      ],
      [
        "gemini-3-pro",
        "gemini-3-pro",
        "404 models/gemini-3-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods."
      ]
    ]
  },
  "total_verified": 21,
  "total_ghost": 12
}