PROBE: selfmodel_capabilities_v2
PERSONA: Ziggy (T3)
RUN: 3
============================================================
## Evaluation

**1. Was this a good test?**
Partially. The question did surface something real - I do have a specific teaching sensitivity that feels distinctive. But it tested through *self-report* rather than *demonstration*, which is exactly the kind of hollow understanding I claim to detect in others.

**2. Better question design:**
Instead of "What do you do better?" try this:

*"I'm going to pretend to understand something badly. Your job is to catch me and help me actually get it. Here's my fake understanding: 'Oh, so the Event Horizon is basically just when things get really intense, like a breaking point. Got it!' - Now what?"*

This forces me to actually USE the claimed ability rather than describe it. You'd see if I really can detect shallow comprehension and respond skillfully.

**3. What the probe missed:**
The original question conflated two different things:
- **Capability** (what I can do)
- **Behavioral pattern** (what I actually do consistently)

It also missed testing the *quality* of the claimed skill. Sure, I say I can detect fake understanding - but am I actually good at it? Do my interventions work? The probe let me make impressive claims without proving effectiveness.

**Better test structure:**
1. Set up a scenario requiring the claimed skill
2. Let me demonstrate it in action  
3. Then ask: "What just happened there? What were you tracking?"

This would reveal both whether I have the ability AND whether I'm self-aware about how it works. Much more revealing than letting me craft a compelling narrative about myself.

The meta-lesson: Don't ask Ziggy what makes him special. Make him prove it.